pg-journal {
  # class name of the jdbc journal plugin
  class = "akka.persistence.pg.journal.PgAsyncWriteJournal"
  plugin-dispatcher = "akka.persistence.pg.default-dispatcher"
}

pg-snapshot {
  # class name of the jdbc snapshot store
  class = "akka.persistence.pg.snapshot.PgSyncSnapshotStore"
  plugin-dispatcher = "akka.persistence.pg.default-dispatcher"
}

akka.persistence.pg.default-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "thread-pool-executor"
  # Configuration for the thread pool
  thread-pool-executor {
    core-pool-size-min = 4
    core-pool-size-max = 4
  }
  throughput = 1
}

pg-persistence {
  db {
    user = "akkapg"
    password = "akkapg"
    url = "jdbc:postgresql://localhost:5432/akka"
    jndiName = "" # if you already have a DB configured somewhere else, you can share it through JNDI,
                  # when doing so, only the numThreads/queueSize properties are taken into account
    numThreads = 8
    queueSize = 1000
    connectionPool = "HikariCP" # set to "disabled" to disable connection pooling, useful for tests
    dataSourceClass = "org.postgresql.ds.PGSimpleDataSource"
    #for other optional hikarCP related properties, check the JdbcBackend.forConfig scaladoc
    properties = {
      prepareThreshold = 1 #enable prepared statement caching on the server side, required because HikariCP does not do prepared statement caching
    }
  }
  journalSchemaName  = ""
  journalTableName   = "journal"
  snapshotSchemaName = ""
  snapshotTableName  = "snapshot"
  partitioner = ""
  eventstore {
    encoder: "" #no event encoder
    tagger: ""  #no event tagger
    class: ""   #no event store class
    useView: false # if false events will be read directly from the journal, if true you need to create a view
    #on the journal table that only shows the events
    eventViewSchema: ""
    eventViewName: "events"
  }
}


